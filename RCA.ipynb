{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root cause analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnlearn as bn\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import sys\n",
    "import numpy\n",
    "\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.skbn as skbn\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "import pyAgrum.lib.image as gph \n",
    "import pyAgrum.lib.bn2graph as bng\n",
    "import pyAgrum.lib.bn_vs_bn as compare\n",
    "import pyAgrum.lib.bn_vs_bn as compare\n",
    "import pydotplus\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get process parameters, create a column representing whether a part is scrap or not\n",
    "with open(\"./Data/causal_data_July.pkl\", \"rb\") as f:\n",
    "    obj = pkl.load(f)\n",
    "    \n",
    "df = pd.DataFrame(obj)\n",
    "\n",
    "def label_race (row):\n",
    "    if ((row['Durchmesser Min. Fübo 1'] >= 0.0008) | (row['Durchmesser Min. Fübo 1'] <= -0.0008)):\n",
    "          return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "#df['is_scrap'] = df.apply (lambda row: label_race(row), axis=1)\n",
    "df['Durchmesser Min. Fübo'] = df.apply (lambda row: label_race(row), axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features of AE signals\n",
    "with open(\"./Data/features_july.pkl\", \"rb\") as f:\n",
    "    obj = pkl.load(f)\n",
    "    \n",
    "features = pd.DataFrame(obj)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge process parameters and features\n",
    "merged = pd.merge(left=df, left_index=True,\n",
    "                  right=features, right_index=True,\n",
    "                  how='inner')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create seperate data samples considering to determine effect of dataset size \n",
    "df.sort_values(by=['DateTime'], inplace=True)\n",
    "#Case 1: All data including process parameters and features of AE signals\n",
    "#df = merged.copy()\n",
    "\n",
    "#case2: scraps only\n",
    "#df_copy = df.loc[df['Durchmesser Min. Fübo'] == 1.0]\n",
    "\n",
    "#case3: all parts without features of AE signals\n",
    "#df_copy = df.copy()\n",
    "\n",
    "#case4: Get all the first parts after dressing\n",
    "#df_copy =  df.loc[df['Anzahl Teile seit letztem Abrichten Sp. 51'] == 1]\n",
    "#del df_copy[\"Anzahl Teile seit letztem Abrichten Sp. 51\"] #because this column will have only 1 value\n",
    "\n",
    "#case5: Get all the last parts before dressing\n",
    "#df_copy =  df.loc[df['Anzahl Teile seit letztem Abrichten Sp. 51'] == 32]\n",
    "#del df_copy[\"Anzahl Teile seit letztem Abrichten Sp. 51\"] #because this column will have only 1 value\n",
    "\n",
    "#case 6: equal number of ok and scrap parts\n",
    "scrap_rows = df.loc[df['Durchmesser Min. Fübo'] == 1.0]\n",
    "good_parts = df.loc[df['Durchmesser Min. Fübo'] == 0.0]\n",
    "good_parts = good_parts.sample(frac=0.0084, replace=True, random_state=1)\n",
    "df_copy = pd.concat([scrap_rows, good_parts])\n",
    "\n",
    "#delete these rows as they are unimportant for RCA as they don't have variance\n",
    "del df_copy[\"DateTime\"]\n",
    "del df_copy[\"CreatedAt\"]\n",
    "del df_copy[\"Drehzahl Abrichten Sp. 51\"]\n",
    "del df_copy[\"Drehzahl Schleifen Sp. 51\"]\n",
    "del df_copy[\"Anz. Abrichthübe bis HK IO Sp. 51\"]\n",
    "del df_copy['Temp. Bett (B02-BT9)_mean']\n",
    "del df_copy['Temp. Innenraum (B02-BT14)_mean']\n",
    "del df_copy['Durchmesser Min. Fübo 1']\n",
    "#del df_copy['is_scrap']\n",
    "\n",
    "#if sample size needs to be modified\n",
    "#df_copy = df_copy.sample(frac=0.1, replace=True, random_state=1)\n",
    "\n",
    "df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max normalisation\n",
    "normalized_df=(df_copy-df_copy.min())/(df_copy.max()-df_copy.min())\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretization -- binning done (for bnlearn library) not needed for Pyagrum, as it has its own interface\n",
    "df_binned = pd.DataFrame()\n",
    "for col in normalized_df.columns:\n",
    "    #special case where 25, 50, 75 percentile are all same\n",
    "    if col == 'Anz. Abrichthübe Sp. 51':\n",
    "        df_binned[col] = normalized_df[col]\n",
    "        continue \n",
    "    col_desc = normalized_df.describe()[col]\n",
    "    bins = [col_desc['min'], col_desc['25%'], col_desc['50%'], col_desc['75%'], col_desc['max']]\n",
    "    labels = [25, 50, 75, 100]\n",
    "    if np.unique(bins).size != len(bins):\n",
    "        labels = labels[0:(np.unique(bins).size -1)]\n",
    "    \n",
    "    df_binned[col] = pd.cut(normalized_df[col], bins=bins, duplicates='drop') #, labels = labels\n",
    "    \n",
    "df_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using Pyagrum Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretization done by PyAgrum library (offers 3 hyper-parameters)\n",
    "discretizer = skbn.BNDiscretizer(defaultDiscretizationMethod='uniform',\n",
    "                                 defaultNumberOfBins=5,\n",
    "                                 discretizationThreshold=25)\n",
    "\n",
    "template = gum.BayesNet()\n",
    "for name in normalized_df.columns:\n",
    "    template.add(discretizer.createVariable(name, normalized_df[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized and discretized data is stored in a template, this needs to stored in a csv file for using pyagrum \n",
    "normalized_df.to_csv('./Data/equal_parts_normalized_df.csv', index=False)\n",
    "file_name = './Data/equal_parts_normalized_df.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ground truth data created by manufacturing expert\n",
    "scrap_analysis_edges = [ ('Peak-Beschleunigung (Zeitbereich) WSS A Schleifen Fübo', 'Unwucht Sp. 51 Leerlauf'), \n",
    "                         ('Unwucht Sp. 51 Leerlauf', 'Peak-Beschleunigung (Zeitbereich) Sp. 51 Leerlauf'), \n",
    "                         ('Unwucht Sp. 51 Leerlauf', 'Anz. Abrichthübe Sp. 51'), \n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Durchmesser Min. Fübo'),\n",
    "                         ('Leistung Sp. 51', 'Durchmesser Min. Fübo'), \n",
    "                         ('Taktzeit gesamt', 'Durchmesser Min. Fübo'), \n",
    "                         ('Taktzeit Abrichten OP1 Sp. 51', 'Taktzeit gesamt'), \n",
    "                         ('Anz. Abrichthübe Sp. 51', 'Taktzeit Abrichten OP1 Sp. 51'),\n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Ext. Durchmesser Min. Fübo 51'), \n",
    "                         ('Taktzeit Schleifen OP1 Sp. 51', 'Taktzeit gesamt'),\n",
    "                         ('Be- / Entladezeit Seite A', 'Taktzeit gesamt'), ('PSH Pos. B5', 'Korr. PSH Sp. 51'), \n",
    "                         ('Ext. Korr. Fübo 1 Sp. 51', 'Durchmesser Min. Fübo'), \n",
    "                         ('Anz. Abrichthübe Sp. 51', 'Taktzeit gesamt'),\n",
    "                         ('Anzahl Teile seit letztem Scheibenwechsel Sp. 51', 'Durchmesser Min. Fübo'), \n",
    "                         ('Stückzahl bis Scheibenwechsel Sp. 51', 'Durchmesser Min. Fübo'), \n",
    "                         ('Anzahl Teile seit letztem Abrichten Sp. 51', 'Durchmesser Min. Fübo'),\n",
    "                         ('Anzahl Teile seit letztem Abrichten Sp. 51', 'Ext. Durchmesser Min. Fübo 51'),\n",
    "                         ('Anzahl Teile seit letztem Scheibenwechsel Sp. 51', 'Stückzahl bis Scheibenwechsel Sp. 51'), \n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Aktueller Durchmesser Sp. 51'),\n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Peak-Beschleunigung (Zeitbereich) Sp. 51 Leerlauf'),#check with Andre\n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Anzahl Teile seit letztem Abrichten Sp. 51'),\n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Taktzeit Abrichten OP1 Sp. 51'),\n",
    "                         ('Korr. Fübo 1 Sp. 51', 'Korr. PSH Sp. 51'), ('Korr. Fübo 1 Sp. 51', 'PSH Pos. B5'),\n",
    "                         ('Leistung Sp. 51', 'Peak-Beschleunigung (Zeitbereich) Sp. 51 Leerlauf'),\n",
    "                         ('Anzahl Teile seit letztem Scheibenwechsel Sp. 51', 'Anz. Abrichthübe Sp. 51'),\n",
    "                         ('Anzahl Teile seit letztem Scheibenwechsel Sp. 51', 'Taktzeit Abrichten OP1 Sp. 51'),\n",
    "                         ('Aktueller Durchmesser Sp. 51', 'Peak-Beschleunigung (Zeitbereich) WSS A Schleifen Fübo'),\n",
    "                         ('Anzahl Teile seit letztem Abrichten Sp. 51', 'Peak-Beschleunigung (Zeitbereich) WSS A Schleifen Fübo'),\n",
    "                         ('Ext. Durchmesser Min. Fübo 51', 'Ext. Korr. Fübo 1 Sp. 51'),\n",
    "                         ('Taktzeit Abrichten OP1 Sp. 51', 'Durchmesser Min. Fübo')\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BN structure from ground truth data\n",
    "bn=gum.BayesNet('ScrapAnalysis')\n",
    "#counter = 1\n",
    "nodes = []\n",
    "for cols in normalized_df.columns:\n",
    "    node = bn.add(gum.LabelizedVariable(str(cols), str(cols)))\n",
    "    nodes.append(node)\n",
    "    \n",
    "import pyAgrum.lib.notebook as gnb\n",
    "for link in scrap_analysis_edges:\n",
    "    bn.addArc(*link)\n",
    "\n",
    "gnb.show(bn,size=\"10!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the plot\n",
    "dot_data = bng.BN2dot(bn,size=\"15!\")\n",
    "dot_data.set_size('\"15,15!\"')\n",
    "dot_data.write_png('ground-truth.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCA model from 3 algorithms (GHC, TS, K2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#use MLFlow to save the results\n",
    "with open(\"mlflow_logs.txt\", 'w') as f:\n",
    "    mlflow.start_run()\n",
    "    learner = gum.BNLearner(file_name, template)\n",
    "\n",
    "    #case 1: GreedyHillClimbing\n",
    "    learner.useGreedyHillClimbing()\n",
    "    bn2 = learner.learnBN()\n",
    "    diff1 = compare.GraphicalBNComparator(bn,bn2).scores()\n",
    "    print('Done with GHC')\n",
    "    diff1['Algorithm'] = 'Greedy Hill Climbing'\n",
    "    dot_data = bng.BN2dot(bn2,size=\"20!\")\n",
    "    dot_data.set_size('\"20,20!\"')\n",
    "    dot_data.write_png('gh-bn.png')\n",
    "    mlflow.log_artifact(\"gh-bn.png\")\n",
    "    \n",
    "    #case 2: TabuList\n",
    "    learner.useLocalSearchWithTabuList()\n",
    "    bn3 = learner.learnBN()\n",
    "    diff2 = compare.GraphicalBNComparator(bn,bn3).scores()\n",
    "    print('Done with TS')\n",
    "    diff2['Algorithm'] = 'Tabu Search'\n",
    "    dot_data = bng.BN2dot(bn3,size=\"20!\")\n",
    "    dot_data.set_size('\"20,20!\"')\n",
    "    dot_data.write_png('ts-bn.png')\n",
    "    mlflow.log_artifact(\"ts-bn.png\")\n",
    "    \n",
    "    #case 2: K2\n",
    "    learner.useK2([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "    bn4 = learner.learnBN()\n",
    "    diff3 = compare.GraphicalBNComparator(bn,bn4).scores()\n",
    "    print('Done with Algo 3')\n",
    "    diff3['Algorithm'] = 'K2'\n",
    "    dot_data = bng.BN2dot(bn4,size=\"20!\")\n",
    "    dot_data.set_size('\"20,20!\"')\n",
    "    dot_data.write_png('k2-bn.png')\n",
    "    mlflow.log_artifact(\"k2-bn.png\")\n",
    "    \n",
    "    #concatenate all dictionaries\n",
    "    dall = {}\n",
    "    dall.update(diff1)\n",
    "    dall.update(diff2)\n",
    "    dall.update(diff3)\n",
    "    mlflow.log_dict(dall, \"results.txt\")\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare ground truth and the learned BN structure from RCA models\n",
    "diff1 = compare.GraphicalBNComparator(bn,bn2).dotDiff()\n",
    "diff1.write_png(\"gt-vs-gh.png\")\n",
    "\n",
    "diff2 = compare.GraphicalBNComparator(bn,bn3).dotDiff()\n",
    "diff2.write_png(\"gt-vs-ts.png\")\n",
    "\n",
    "diff3 = compare.GraphicalBNComparator(bn,bn4).dotDiff()\n",
    "diff3.write_png(\"gt-vs-k2.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                   \n",
    "    title:         Title for the heatmap. Default is None.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names)==cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        #Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        #if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf)==2:\n",
    "            #Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1,1] / sum(cf[:,1])\n",
    "            recall    = cf[1,1] / sum(cf[1,:])\n",
    "            f1_score  = 2*precision*recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy,precision,recall,f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize==None:\n",
    "        #Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks==False:\n",
    "        #Do not show categories if xyticks is False\n",
    "        categories=False\n",
    "\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.savefig('heatmap-tcdf-vs-gt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for diff in [diff1,diff2,diff3]:\n",
    "    #get the tp, tn, fp, fn values for calculating the confusion matrix\n",
    "    json_str = json.dumps(diff)\n",
    "\n",
    "    #load the json to a string\n",
    "    resp = json.loads(json_str)\n",
    "\n",
    "    tp = resp['count']['tp']\n",
    "    tn = resp['count']['tn']\n",
    "    fp = resp['count']['fp']\n",
    "    fn = resp['count']['fn']\n",
    "    y_true = [tp, fp]\n",
    "    y_pred = [fn, tn]\n",
    "    labels = [\"True Pos\",\"False Neg\",\"False Pos\",\"True Neg\"]\n",
    "    categories = [\"True\", \"False\"]\n",
    "    cf_matrix = np.column_stack((y_true, y_pred))\n",
    "\n",
    "    make_confusion_matrix(cf_matrix, \n",
    "                          group_names=labels,\n",
    "                          categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAgrum.lib.explain as explain\n",
    "bn2=learner.learnBN()\n",
    "print(\"Learned in {0}ms\".format(1000*learner.currentTime()))\n",
    "gnb.sideBySide(bn3,explain.getInformation(bn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie=gum.LazyPropagation(bn3)\n",
    "ie.makeInference()\n",
    "print(ie.posterior(bn3.idFromName(\"Durchmesser Min. Fübo\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInference(bn3,evs={},targets={\"Durchmesser Min. Fübo\",\"Anz. Abrichthübe Sp. 51\"},size=\"11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAgrum.lib.explain as explain\n",
    "explain.showInformation(bn3,{},size=\"14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInference(bn2,evs={},size=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.sideBySide(bn2, gum.MarkovBlanket(bn2, 'Durchmesser Min. Fübo'), captions=[\"Learned Bayesian network\", \"Markov blanket of 'Durchmesser Min. Fübo'\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gum.MarkovBlanket(bn4, 'Durchmesser Min. Fübo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn2.generateCPTs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.use3off2()\n",
    "learner.useNMLCorrection()\n",
    "print(learner)\n",
    "ge3off2=learner.learnMixedStructure()\n",
    "ge3off2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.useMIIC()\n",
    "learner.useNMLCorrection()\n",
    "print(learner)\n",
    "gemiic=learner.learnMixedStructure()\n",
    "gemiic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAgrum.causal as csl\n",
    "import pyAgrum.causal.notebook as cslnb\n",
    "\n",
    "target=\"Durchmesser Min. Fübo\"\n",
    "evs=\"Anz. Abrichthübe Sp. 51\"\n",
    "\n",
    "model=csl.CausalModel(bn2)\n",
    "cslnb.showCausalImpact(model,target, {evs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ie=gum.LazyPropagation(bn)\n",
    "ie2=gum.LazyPropagation(bn3)\n",
    "p1=ie.evidenceImpact(target,[evs])\n",
    "p2=gum.Potential(p1).fillWith(ie2.evidenceImpact(target,[evs]),[target,evs])\n",
    "errs=((p1-p2)/p1).scale(100)\n",
    "quaderr=(errs*errs).sum()\n",
    "gnb.sideBySide(p1,p2,errs,quaderr,\n",
    "              captions=['in original model','in learned model','relative errors','quadratic error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-POC]",
   "language": "python",
   "name": "conda-env-.conda-POC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
